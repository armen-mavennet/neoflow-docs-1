{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>In today\u2019s world, energy commodities play a critical role in powering economies and societies. Recognizing their significance, Neoflow has created a platform that pioneers the creation of a comprehensive digital representation for energy commodities. Neoflow enables multiple participants in the energy value chain (producers, pipelines, refineries, utilities, industrial consumers, LNG infrastructure operators) to create an end-to-end digital representation of the lifecycle of energy commodities.</p> <p>Neoflow relies on the interoperable W3C standards of Decentralized Identifiers (DID) and Verifiable Credentials (VC) to create trusted digital representation of the energy lifecycle, from production and processing through trading, transportation, and consumption.</p> <p>The initial focus of the platform is to create a commodity Digital Passport, complete with the record of attributes and events, collectively built by value chain participants. Digital Passport enables a variety of digitization opportunities for the industry stakeholders, ranging from Digital Border Clearance and Regulatory reporting to Contract Automation and Environmental Impact Differentiation.</p>"},{"location":"api-user-guide/","title":"API User Guide","text":"<p>This document provides the guide to getting started on the Neoflow platform and building integrations with the REST APIs exposed. The intended audience is a software developer well acquainted with REST APIs and JSON. With that knowledge, the Swagger API Documentation will be the best place to start testing and exploring the platform APIs.</p>"},{"location":"api-user-guide/#swagger-api-documentation","title":"Swagger API Documentation","text":"<p>The REST APIs in Neoflow follow the OpenAPI standard specifications. These API endpoints are documented using the OpenApi Specification.</p> <p>Swagger URL - https://api.mavennet.com/ </p>"},{"location":"api-user-guide/#authentication","title":"Authentication","text":"<p>As Neoflow is an invite-only platform, client credentials are required to integrate with Neoflow REST APIs. API calls without the authentication token will fail.  </p> <p>Please visit https://neoflow.energy to begin the onboarding process.</p>"},{"location":"api-user-guide/#products-api","title":"Products API","text":"<p>A product can be any petroleum-based product, such as crude oil streams, bitumen or natural gas. The product information is stored in the form of a verifiable credential issued by the organization who created it.</p> <p>Below are the set of functions that can be carried out on the product. Please be sure to have the authentication material at hand before beginning to work with the API endpoints.</p>"},{"location":"api-user-guide/#creation","title":"Creation","text":"<p>The products can be created and fetched in the Neoflow platform using below set of API endpoints. When a product is created, a corresponding creation of the product event is also stored in Neoflow. Each product and the event is uniquely identified with a UUID.</p> <pre><code>POST /v1/products  \nGET /v1/products  \nGET /v1/products/{id}  \n</code></pre>"},{"location":"api-user-guide/#transport","title":"Transport","text":"<p>The custodian organization transports the product from one location to another. This movement is recorded in Neoflow in the form of <code>start</code> and <code>end</code> transport events. Bill of Lading details are captured at during this process. Transport events support correction of the details using the VC revocation standards.</p> <pre><code>POST /v1/products/transport  \nPUT /v1/products/transport  \n</code></pre>"},{"location":"api-user-guide/#share","title":"Share","text":"<p>The owner of the product can share or unshare the product with another organization(s). If the product is shared, an organization can access all the product details such as product's physical and chemical specifications, associated events with their location of occurrence, origin, product's composition/traceablility hierarchy and uploaded documents if any.</p> <pre><code>POST /v1/products/share  \nGET /v1/products/share  \nDELETE /v1/products/share  \n</code></pre>"},{"location":"api-user-guide/#http-status-codes-errors","title":"HTTP Status Codes &amp; Errors","text":"<p>Neoflow uses conventional HTTP response codes to indicate the success or failure of an API request. An exhaustive list for the same can be found here.</p>"},{"location":"api-user-guide/#support","title":"Support","text":"<p>Please contact support at support@neoflow.energy.</p>"},{"location":"data-governance/","title":"Data Governance","text":"<p>The Neoflow ecosystem depends on industry and government stakeholders working together to enable the creation of a digital representation of an asset complete with lifecycle events and attributes. In this way, a viable ecosystem necessitates value chain participants who are actively part of the business workflow, read, write and commit data to the platform. These participants may run their own nodes or may have their nodes operated by Neoflow. In addition, there will be value chain ecosystem users who leverage data for the purposes of regulation, value chain monitoring or to gain market intelligence.</p> <p>The table below outlines the different network participants, their roles and permissions within the system, as well as examples of their function in the Oil &amp; Gas value chain.</p> System Roles Permissions Role within the Oil &amp; Gas Value Chain Value Chain Participants Data providers, owners and users (node operators) Read, write and commit transactions on the system Oil &amp; Gas producer, shipper, pipeline, custom broker, etc. Value Chain Ecosystem Data users Access the system and see transactions for the purposes of monitoring U.S. Customs and Border Protection (CBP) Technology providers Infrastructure and applications development, IT support and additional services No read, write or transaction issuing permissions. Only access to sample data to enhance or roll out new features with data holders\u2019 consent. No permission to share beyond consolidated industry reports and anomaly detection. Third party service providers"},{"location":"data-governance/#data-visibility","title":"Data Visibility","text":"<p>To provide user with transparency on product lifecycle and business data, as well as ability to automate order, contract and digital border clearance, Neoflow stores five types of data. The diagram below illustrates the different layers of data and the respective access restrictions within the ecosystem. It is important to note that protected data never travels to other parties unless explicitly shared and public data is public only within Neoflow.</p> <p></p> <p>For the purposes of illustration, we have included some examples of the types of data that would fall under each bucket in the table below.</p> Data Types Description Accessibility Examples Product Tombstone Data Used for visualizing complete product lifecycle Protected <ul><li>High level product composition and history</li></ul> Product Detailed Data Used for visualizing complete product lifecycle in details. Contains product sensitive data Protected <ul><li>Transformation events, specifications, locations and timestamps, etc.</li></ul> Commercially Sensitive Data Used for automating order, contract and border clearance. Contains commercially sensitive data Private <ul><li>Digital contract (parties, dates, volume, price, etc.) - co-owned by the two contracting parties</li><li>Import declaration</li></ul> Company Info Used for automating order, contract and border clearance Protected <ul><li>Company name, address, postal code, etc.</li></ul> Aggregate Data Used for data analytics and value chain insights Public within Neoflow <ul><li>Aggregated supply and demand data per period</li><li>General industry trends and analytics insights</li></ul>"},{"location":"data-governance/#data-sharing-and-accessibility","title":"Data Sharing and Accessibility","text":"<p>For each network participants, Neoflow enforces strict rules listed in the below table for data privacy and accessibility. Neoflow also ensures that all Product Detailed Data owners can see which network participant holds a Degree-2 accessibility, and can grant and revoke the access at all times. </p> Network Participants Data Type Permission Read if a related product has been shared(Degree-1) Read if the owner grants access explicitly(Degree-2) Can only read owned data(Degree-3) Read and download(Degree-4) Value Chain Stakeholders Product Tombstone Data \u2705 Product Detailed Data \u2705 Commercially Sensitive \u2705 Company Info \u2705 Aggregated Data \u2705 Value Chain Ecosystem Product Tombstone Data \u2705 Product Detailed Data \u2705 Commercially Sensitive \u2705 Aggregated Data \u2705 Technology Providers Product Tombstone Data Permitted to collect and use the data samples to support Neoflow features;  NOT Permitted to share with 3rd parties beyond consolidated industry reports and anomaly detection Product Detailed Data Commercially Sensitive Company Info Aggregated Data"},{"location":"key-concepts/","title":"Key Concepts","text":"<p>The Neoflow platform relies on a set of standard specifications developed under W3C to enable interoperability with decentralized and traditional IT systems.</p>"},{"location":"key-concepts/#decentralized-identity-did","title":"Decentralized Identity (DID)","text":"<p>Organizations interacting with the Neoflow platform use Decentralized Identifiers (DIDs) as their Organizational Identifiers Decentralized identifiers  are a type of digital identity that allow individuals, organizations, and things to have control over their own digital identity, without relying on centralized authorities or third-party intermediaries. In supply chains, DIDs can be used to securely and verifiably track the movement of goods from one stage of the supply chain to another. This provides a number of benefits, including increased transparency, security, and efficiency.</p> <p>One of the main advantages of using DIDs on supply chains is that they provide a secure and tamper-proof record of each stage of the supply chain. This can help to prevent fraud, counterfeiting, and other forms of supply chain malpractice. DIDs can also be used to ensure that goods are produced and transported in compliance with relevant regulations and standards, which can help to increase consumer trust and confidence in the supply chain.</p> <p>In addition to these benefits, DIDs can also help to increase efficiency in supply chains by reducing the need for intermediaries and middlemen. By providing a secure and transparent record of each stage of the supply chain, DIDs can help to streamline the process of tracking and verifying goods as they move from one stage to another. This can help to reduce costs, increase speed, and improve overall supply chain performance.</p>"},{"location":"key-concepts/#verifiable-credential-vc-and-verifiable-presentation-vp","title":"Verifiable Credential (VC) and Verifiable Presentation (VP)","text":"<p>Verifiable credentials are digital representations of a person or organization's identity, qualifications, or other attributes that have been cryptographically signed by a trusted issuer. They can be used to securely and verifiably attest to a wide range of information, from a person's age or vaccination status to a company's compliance with environmental or labor standards.</p> <p>Neoflow uses verifiable credentials to verify the identity and qualifications of suppliers, as well as the authenticity and provenance of products as they move through the supply chain. By attaching verifiable credentials to each stage of the supply chain, from raw materials to finished products, it becomes possible to track the movement of goods and ensure that they meet the necessary quality and safety standards.</p> <p>Verifiable credentials can also help to address some of the major challenges in supply chain traceability, such as the lack of trust and coordination between different parties. By enabling the secure and transparent sharing of information between suppliers, manufacturers, distributors, and retailers, verifiable credentials can help to build trust and facilitate more effective collaboration. This can lead to a more efficient and resilient supply chain, as well as increased consumer confidence and loyalty.</p>"},{"location":"key-concepts/#traceability-vocabulary-and-interoperability-profile","title":"Traceability Vocabulary and Interoperability Profile","text":"<p>The schemas used for the verifiable credentials are defined in the traceability vocabulary being developed under W3C-CCG Traceability Vocabulary.The vocabularies for relevant value chain documents, such as crude oil and natural gas certificates of origin, delivery tickets, inspection reports and events are fully supported on the platform.</p> <p>Neoflow uses the W3C-CCG Traceability Interop profile - as an interoperable API specification for issuing, transmitting and verifying the Verifiable Credentials.</p>"},{"location":"platform-overview/","title":"Platform Overview","text":"<p>Neoflow is a platform that allows users to create digital credentials of energy commodities with verifiable and end-to-end information of lifecycle events, attributes, ownership, custody, origin and location. </p> <p>Key information in the value chain of a commodity, such as bills of lading, delivery tickets, certificates of origin, among others, are digitized to streamline data exchange and automate regulatory and import reporting processes. </p> <p></p> <p>Neoflow creates a standards-based protocol for exchange of digital data representing an energy commodity. At its core, the platform is based on a combination of consortium blockchain and emerging W3C standards of Decentralized Identifiers (DID) and Verifiable Credentials (VC).</p> <p>The use of blockchain, VC, and DID standards allows various value chain stakeholders (Producers, Transporters, Refineries, Regulators and Service Providers) to safely and securely exchange data in a standardized manner. The end result is a digital representation of the commodity, it's attributes and lifecycle history that is built together and verified by multiple applicable stakeholders. </p> <p>A common digital representation of the physical commodity (a digital twin, or a digital passport) in turn enables a variety of digital innovations, or use cases that would otherwise be not feasible.</p> <p>The following are the key features that the platform supports.</p>"},{"location":"platform-overview/#events","title":"Events","text":"<p>In the context of Neoflow, a Neoflow event is intended to digitally represent a specific physical event in the lifecycle of an energy commodity (extraction, dilution, pooling, refinement). Along with event-specific attributes, a Neoflow event captures the date, time, and location of the event as well as a cryptographic link to the DID of the organization that published the event. </p> <p>The lifecycle of the commodity is mapped with below set of supply chain events on the Neoflow platform. These events are compatible with GS1 EPCIS.</p> <ul> <li>Creation of commodity (or product)</li> </ul> <ul> <li>Delivery Scheduled</li> <li>In Transit</li> <li>Delivered</li> <li>CBP Entry</li> </ul> <p>Events are exposed as Verifiable Credentials that are self-issued by the event creator and are defined on the Traceability-Vocab.</p>"},{"location":"platform-overview/#proof-of-origin-composition","title":"Proof of Origin &amp; Composition","text":"<p>Production and transformation records are standardized and updated in real-time. Neoflow's underlying blockchain technology enables the creation of a trusted digital history that is attested by each party in the value chain and is impossible to forge. </p> <p>Each data element, timestamp and actor in the digital certificate of origin and composition is cryptographically proven and can be easily verified by independent actors (e.g., border control, regulatory agencies, external auditors). </p>"},{"location":"platform-overview/#certificate-of-origin","title":"Certificate of Origin","text":"<p>The certificate of origin includes relevant product attributes such as HS code, physical and chemical product specifications, type of commodity, volume, among others. </p> <p>The lifecycle of the product is presented to outline its detailed composition from previous transformation events, along with details of the products that were used in its transformation. </p> <p></p>"},{"location":"platform-overview/#real-time-analytics","title":"Real-Time Analytics","text":"<p>The core functionality of Neoflow provides trusted real-time data. Coupled with analytics, this provides users with actionable insights such for: * Evidence-based policy making * Descriptive and predictive insights specific to supply and demand management * Detection and alerts of anomalies in real-time</p>"},{"location":"platform-overview/#details","title":"Details","text":"<p>Neoflow has pre-built dashboards that are customizable and provide granular data, specific to an organization's role in the value chain and a user's role. In this way, visualizing and responding dynamically to events or alerts is easier and faster.  </p> <p></p>"},{"location":"security-and-data-privacy/","title":"Security and Data Privacy","text":""},{"location":"security-and-data-privacy/#compliance","title":"Compliance","text":"<p>This section is to provide details on data regulations which Neoflow follows to ensure data privacy and security. Please note that, PIPEDA and Privacy Act* do not apply directly to the use cases, but Neoflow continues to follow the principles to enhance data privacy. This section is meant to serve as a framework for data regulation to be followed, however it will be reviewed by a legal professional before it is finalized.</p> <p>Neoflow also follows a set of broadly accepted technology standards to methodically ensure appropriate level of security to avoid the following threats: * Unauthorized access and privilege escalation * Eavesdropping of information that a particular organization or 3rd party should not have access to * Tampering of information * Denial of Service Attacks (DoS)</p> <p>Neoflow is intended to be deployed on NIST compliant infrastructure and designed to be compliant with</p> <ul> <li>FIPS 180-4</li> <li>FIPS 186-5</li> <li>FIPS 197</li> </ul> <p>Neoflow Managed Infrastructure is deployed on sandboxed environments and are deployed on AWS.</p> <p>Self Managed infrastructure may be deployed on any cloud provider/ on-premise infrastructure and the security is the responsibility of the managing organization.</p> Document Description SOC 2 Type 1 Developed by the American Institute of CPAs (AICPA), SOC 2 defines criteria for managing customer data based on five \u201ctrust service criteria\u201d \u2014 security, availability, processing integrity, confidentiality and privacy. SOC 2 Type 2 Developed by the American Institute of CPAs (AICPA), SOC 2 defines criteria for managing customer data based on five \u201ctrust service criteria\u201d \u2014 security, availability, processing integrity, confidentiality and privacy. Red Team Attestation In November 2022, Assured Information Security conducted a functional, operational, and security assessment of Neoflow. Testing and evaluation (T&amp;E) consisted of validating the technology\u2019s overall functionality, identifying potential vulnerabilities in credential workflows and their associated communications, and evaluating the privacy implications associated with the use of the technology."},{"location":"security-and-data-privacy/#common-questions","title":"Common Questions","text":"<p>Neoflow has been built with cybersecurity and data privacy at the core</p> What type of information does Neoflow store and manage? <p>Neoflow enables industry participants to store and manage information related to shipments of Crude Oil and Natural Gas (e.g., production, blending, dilution, storage, transportation, border declaration, refinement).</p> Who is my data shared with? <p>No data is shared unless explicitly requested by the organization that owns the data. For example, importer requests Neoflow for the shipment information to be shared with CBP once there is intent to import.</p> Does Neoflow store PII (Personally identifiable information)? <p>No. Neoflow does not request, store or manage PII.</p> Does Neoflow store PHI (Protected health information)? <p>No. Neoflow does not request, store or manage PHI.</p> Did Neoflow undergo security testing? <p>Neoflow has successfully completed the U.S. Department of Homeland Security (DHS) platform review process, called Red Team Testing. This process is designed to perform an independent comprehensive review of system architecture, security, scalability and standards compliance (NIIST/FISMA) in order to ensure Neoflow is ready to be operated in production by the U.S. DHS. Please refer to Page 10 of this document for Red Team Assessment Results.</p> Does Neoflow have technology controls in place to protect against the OWASP Top 10 attacks? <p>Yes. Neoflow is protected against the OWASP Top 10 attacks through the use of modern frameworks to alleviate a class of attack (for example, SQL injection and XSS), relying on load balancers and AWS shield to protect against DDOS attacks. Neoflow infrastructure is also Highly Available with a multiple Availability Zones setup in accordance with the AWS well architected framework.</p> Does Neoflow have a Disaster Recovery Plan and a Business Continuity Plan? <p>Yes. Neoflow is built with 24-hour RTO and 4-hour RPO SLAs. we are currently finalizing  Disaster Recovery and Business Continuity Plans, and both will be complete prior to the start of the Tech Demo/Pilot. Once complete, it will be shared with current and prospective clients.</p> What is the data ownership, security and data sharing model within Neoflow? <p>Proprietary information is held securely and privately with the owner of the data retaining ownership of its information at all times.</p> <p>When the data owner chooses to share the data with another organization, the selected data is shared with that organization securely. Sharing of data occurs only at the explicit request of the data owner.</p> Will government agencies (e.g., US CBP, CER) have access to data? <p>No entity has access to any data without the express permission of the owner of the data and it is solely at the discretion of the data owner when and what information is shared with CBP.</p> <p>Government agencies like CBP will only be able to access the information that they are given permission to access by the owner of the data.  This permission by the owner will be for certain information required to be shared if the owner of the data will be importing the product and claiming USMCA such as pre-arrival information and the information required to make the appropriate Customs entry and USMCA preference.</p> <p>The parameters around the access given to each agency will be pre-determined and parties using Neoflow will be aware of what information can be shared.</p> What data is each party responsible for? <p>Each party owns and is responsible for its own information which cannot be altered by any other party.</p> <p>Each party\u2019s information is added to the life cycle of the product but cannot be shared with any other party unless expressly shared by the owner or as expressly allowed within the parameters of CBP\u2019s authority to view.</p> <p>For example, when the producer creates a record of the batch produced, once the ownership is transferred to a downstream participant (e.g., refinery importing the batch into the US), the producer does not have visibility to data that is entered at that point.</p> Where is my data stored? <p>Firstly, each organization using our service is set up as an isolated Tenant with a separate AWS account in accordance with AWS Multi Account Best practices. Within each tenant, all private data is encrypted and stored on a private subnet AWS RDS while all shared data is encrypted and stored on the Neoflow core AWS Tenant.</p> <p>Neoflow relies on AWS Security best Practices and has passed a Red Team Security review by the U.S. DHS. The Red Team attestation letter can be found on page 10 of this document.</p> Does anyone from Neoflow have access to my data? <p>At Neoflow, access to production data is limited to two designated Operations and Support employees.</p> <p>These employees do not access data under normal operations.</p> <p>Data access is required for deployment and support activities.</p> <p>Neoflow operates a comprehensive access control mechanism and monitoring system to ensure that access to the data is only granted to authorized personnel. AWS Control Tower is used to enforce access controls and to ensure that your data remains secure.</p> <p>Neoflow maintains a detailed audit log for all access to production data, which is available upon request.</p> <p>All policies and procedures regarding production data adhere to SOC 2 Type II standard.</p> What are Neoflow policies regarding Data Access and Data Privacy? <p>Neoflow follow the full set of SOC 2 policies and procedures, as evidenced by our SOC 2 Type II audit. This includes (but is not limited to) the following: Information Security Policy, Access Control Policy, Password Policy, Data Classification Policy, Physical Security Policy, Acceptable Use Policy, Backup Policy, Logging and Monitoring Policy, Risk Management Policy, Incident Response Policy, Business Continuity Plan, among other relevant policies.</p>"}]}